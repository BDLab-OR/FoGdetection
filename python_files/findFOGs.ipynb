{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import resampy as rs \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa as tsa \n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_directory = '/Users/alexastefanko/lab/FoGdetection/Subjects'\n",
    "output_directory = '/Users/alexastefanko/lab/FoGdetection/Output/'\n",
    "sample_rate = 128\n",
    "step = 200\n",
    "\n",
    "r_acc_ap_col = \"R_acc\"; #Column name for right accelerometer anterior-posterior\n",
    "l_acc_ap_col = \"L_acc\"; #Column name for left accelerometer anterior-posterior\n",
    "r_gyr_ml_col = \"R_gyr\"; #Column name for right gyroscope mediolateral\n",
    "l_gyr_ml_col = \"L_gyr\"; #Column name for left gyroscop mediolateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fog:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.very_short_fog = None\n",
    "        self.short_fog = None\n",
    "        self.long_fog = None\n",
    "        self.very_long_fog = None\n",
    "        self.total = None\n",
    "        self.nn = None\n",
    "        self.mm = None\n",
    "    \n",
    "    def set_nn(self, n):\n",
    "        self.nn = n\n",
    "        \n",
    "    def set_very_short(self, num):\n",
    "        self.very_short_fog = num\n",
    "        \n",
    "    def set_short(self, num):\n",
    "        self.short_fog = num\n",
    "        \n",
    "    def set_long(self, num):\n",
    "        self.long_fog = num\n",
    "        \n",
    "    def set_very_long(self, num):\n",
    "        self.very_long_fog = num\n",
    "        \n",
    "    def set_mm(self, mm):\n",
    "        self.mm = mm\n",
    "    \n",
    "    def set_total(self, num):\n",
    "        self.total = num\n",
    "    \n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"very short: \" + str(self.very_short_fog))\n",
    "        print(\"short: \" + str(self.short_fog))\n",
    "        print(\"long: \" + str(self.long_fog))\n",
    "        print(\"very long: \" + str(self.very_long_fog))\n",
    "        \n",
    "#Getters\n",
    "        \n",
    "    def get_nn():\n",
    "        return self.NN\n",
    "    \n",
    "    def get_very_short():\n",
    "        return self.very_short_fog\n",
    "        \n",
    "    def get_short():\n",
    "        return self.short_fog \n",
    "        \n",
    "    def get_long():\n",
    "        return self.long_fog\n",
    "        \n",
    "    def get_very_long():\n",
    "        return self.very_log_fog\n",
    "        \n",
    "    def get_mm():\n",
    "        return self.MM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files(directory):\n",
    "    for dir_name, subdir_list, file_list in os.walk(directory):\n",
    "        return [os.path.join(dir_name, name) for name in file_list if name.endswith(\".csv\")] \n",
    "        \n",
    "def get_starter_idx(data):\n",
    "    r_ml = data[0]\n",
    "    mean_r = np.mean(r_ml)\n",
    "    r_for_cov = [x - mean_r for x in r_ml]\n",
    "    \n",
    "    l_ml = data[1]\n",
    "    mean_l = np.mean(l_ml)\n",
    "    l_for_cov = [x - mean_l for x in l_ml]\n",
    "\n",
    "    num_points = len(r_ml)\n",
    "    array = np.array([r_ml, l_ml])\n",
    "        \n",
    "    #R and L angular velocities cross-correlation to find a delay between two\n",
    "    cross_cov = np.correlate(r_for_cov, l_for_cov, \"full\")\n",
    "    shifter = 0\n",
    "    for idx, num in enumerate(cross_cov):\n",
    "        if num == np.max(cross_cov):\n",
    "            shifter = idx\n",
    "    \n",
    "    starter = round(abs(shifter - (len(cross_cov)/2)))\n",
    "    return starter\n",
    "\n",
    "def create_corr_log(corr_data, threshold):\n",
    "    log = [None] * len(corr_data)\n",
    "    idx = 0\n",
    "    for i in corr_data:\n",
    "        if i < threshold:\n",
    "            log[idx] = 1\n",
    "        else:\n",
    "            log[idx] = 0\n",
    "        idx = idx + 1\n",
    "    return log\n",
    "    \n",
    "def correlation_based_method(starter, filtered_data):\n",
    "    #Sync R and L after correction for delay\n",
    "    t_sensor_1 = filtered_data[0][starter:]\n",
    "    t_sensor_2 = filtered_data[1][:len(filtered_data[1]) - starter]\n",
    "    correlated_sensor_data = []\n",
    "    \n",
    "    #Ensure bouts have sufficient data\n",
    "    range_intervals = list(range(0, len(t_sensor_1) - (step+1), step))\n",
    "    if len(t_sensor_1) > (step*5):\n",
    "        for i in range(len(range_intervals) - 1):\n",
    "            start = range_intervals[i]\n",
    "            end = range_intervals[i+1]\n",
    "            corr = np.corrcoef(t_sensor_1[start:end], t_sensor_2[start:end])\n",
    "            correlated_sensor_data.append(corr[0][1])\n",
    "        abs_corr_sensor_data = np.absolute(correlated_sensor_data)\n",
    "        corr_log = create_corr_log(abs_corr_sensor_data, 0.5)\n",
    "        return corr_log\n",
    "    else:\n",
    "        raise ValueError(\"Error: There is not enough data to calculate FOG. Please ensure each bout is longer than 10 seconds or sample more often\")\n",
    "\n",
    "def fft_method(starter, data, len_data):\n",
    "    corrected_r_ap = data[0][starter:]\n",
    "    corrected_l_ap = data[1][:len_data - starter]\n",
    "    if len(corrected_r_ap) > step*5:\n",
    "        range_intervals = list(range(0, len(corrected_r_ap) - (step+1), step))\n",
    "        ratio_r = []\n",
    "        ratio_l = []\n",
    "        for i in range(len(range_intervals) - 1):\n",
    "            start = range_intervals[i]\n",
    "            end = range_intervals[i+1]\n",
    "            l = len(corrected_r_ap[start:end])\n",
    "            list_step = int(round(l/step))\n",
    "            f = list(range(0, (list_step*(l)), list_step))\n",
    "            lf = f.index(3)\n",
    "            hf = f.index(10)\n",
    "            llf = f.index(0)\n",
    "            detrend_r = sp.signal.detrend(corrected_r_ap[start:end])\n",
    "            detrend_l = sp.signal.detrend(corrected_l_ap[start:end])\n",
    "            p_r = abs(np.fft.fft(detrend_r))/(l/2)\n",
    "            p_l = abs(np.fft.fft(detrend_l))/(l/2)\n",
    "            ratio_r.append(sum(p_r[lf:hf+1])**2/sum(p_r[llf:lf+1])**2)\n",
    "            ratio_l.append(sum(p_l[lf:hf+1])**2/sum(p_l[llf:lf+1])**2)\n",
    "        \n",
    "        perc = [None] * len(ratio_r)\n",
    "        for j in range(len(ratio_r)):\n",
    "            # Threshold on frequency ratio based on FFT\n",
    "            if ratio_r[j]>10 or ratio_l[j] > 10:\n",
    "                perc[j] = 1\n",
    "            else:\n",
    "                perc[j] = 0\n",
    "    else:\n",
    "        raise ValueError(\"Error: There is not enough data to calculate FOG. Please ensure each bout is longer than 10 seconds or sample more often\")\n",
    "    return perc\n",
    "\n",
    "def find_log_overlap(corr_log, fft_log):\n",
    "    final_log = [None] * len(corr_log)\n",
    "    for i in range(len(corr_log)):\n",
    "        if corr_log[i] == 1 and fft_log[i] == 1:\n",
    "            final_log[i] = 1\n",
    "        else:\n",
    "            final_log[i] = 0\n",
    "    return final_log\n",
    "\n",
    "def merge_one_two_second(log):\n",
    "    #this log should be its own data struct\n",
    "    merged_log = log \n",
    "    episodes = [i for i, x in enumerate(log) if x == 1]\n",
    "    episodes_diff = np.diff(episodes)\n",
    "    indices_diff_1 = [i for i, x in enumerate(episodes_diff) if x == 2]\n",
    "    indices_diff_2 = [i for i, x in enumerate(episodes_diff) if x == 3]\n",
    "    for idx in indices_diff_1: \n",
    "        merged_log[episodes[idx]+1] = 1 \n",
    "    for idx_2 in indices_diff_2:\n",
    "        merged_log[episodes[idx_2]+1] = 1\n",
    "        merged_log[episodes[idx_2]+2] = 1\n",
    "    return merged_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files = get_csv_files(study_directory)\n",
    "dataframes = [pd.read_csv(file) for file in subject_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very short: 0\n",
      "short: 2\n",
      "long: 6\n",
      "very long: 0\n",
      "very short: 0\n",
      "short: 2\n",
      "long: 6\n",
      "very long: 0\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "fogs = []\n",
    "for df in dataframes:\n",
    "    fog = Fog(subject_files[x])\n",
    "    \n",
    "    r_acc_ap = df[r_acc_ap_col].values\n",
    "    l_acc_ap = df[l_acc_ap_col].values\n",
    "    r_gyr_ml = df[r_gyr_ml_col].values\n",
    "    l_gyr_ml = df[l_gyr_ml_col].values\n",
    "    \n",
    "    #Resample the data to 200 \n",
    "    r_ml = rs.resample(r_gyr_ml, sample_rate, step)\n",
    "    l_ml = rs.resample(l_gyr_ml, sample_rate, step)\n",
    "    r_ap = rs.resample(r_acc_ap, sample_rate, step)\n",
    "    l_ap = rs.resample(l_acc_ap, sample_rate, step)\n",
    "    \n",
    "    #apply low-pass butterworth filter\n",
    "    a,b = sp.signal.butter(4,5/(200/2))\n",
    "    \n",
    "    #difference is here\n",
    "    sensor_data_filtered=sp.signal.filtfilt(a,b,[r_ml, l_ml], padtype = 'odd', padlen=3*(max(len(b),len(a))-1));\n",
    "    \n",
    "    #correlation-based method\n",
    "    starter_idx = get_starter_idx([r_ml, l_ml])\n",
    "    starter = round(abs(starter_idx))\n",
    "    corr_log = correlation_based_method(starter, sensor_data_filtered)\n",
    "    \n",
    "    #fft-based method\n",
    "    fft_log = fft_method(starter, [r_ap, l_ap], len(sensor_data_filtered[0]))\n",
    "    \n",
    "    #Find places where logs agree\n",
    "    final_log = find_log_overlap(corr_log, fft_log)\n",
    "    \n",
    "    #Merge FOGS with one or two second apart\n",
    "    merged_log = merge_one_two_second(final_log)\n",
    "    \n",
    "    fog.set_nn(merged_log.count(1))\n",
    "    fog.set_mm(len(merged_log))\n",
    "    \n",
    "    nonzero_idxs = [i for i, x in enumerate(np.diff(merged_log)) if x != 0]\n",
    "    logical_arr = [None] * len(nonzero_idxs)\n",
    "    for idx, val in enumerate(nonzero_idxs):\n",
    "        logical_arr[idx] = merged_log[val]\n",
    "    dist_between_idxs = np.diff(nonzero_idxs)\n",
    "    compare = [logical_arr, dist_between_idxs.tolist()]\n",
    "    \n",
    "    very_short = 0\n",
    "    short = 0\n",
    "    long = 0\n",
    "    very_long = 0\n",
    "    \n",
    "    for yes, idx in zip(logical_arr, dist_between_idxs.tolist()):\n",
    "        if yes==1 and idx == 1:\n",
    "            very_short = very_short + 1\n",
    "        elif yes==1 and idx>=2 and idx<=5:\n",
    "            short = short + 1\n",
    "        elif yes==1 and idx > 5 and idx<=30:\n",
    "            long = long + 1\n",
    "        elif yes==1 and idx > 30:\n",
    "            very_long = very_long + 1\n",
    "    \n",
    "    fog.set_very_short(very_short)\n",
    "    fog.set_short(short)\n",
    "    fog.set_long(long)\n",
    "    fog.set_very_long(very_long)\n",
    "    \n",
    "#     fog.set_total(100*((sum()-sum(IFOG.Very_short_FOG,'omitnan'))/sum(IFOG.MM,'omitnan')))\n",
    "    \n",
    "    \n",
    "    fog.print_self()\n",
    "    fogs.append(fog)\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
